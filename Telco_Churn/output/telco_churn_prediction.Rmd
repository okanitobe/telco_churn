---
title: "Supervised Learning Project: Predicting Churn and Comparing Models"
output: html_notebook
---

## Load libraries
```{r}
library(readxl)
library(tidyverse)
library(rpart)
library(caret)
library(adabag)
library(ggpubr)
library(pROC)
```

## Import Data
```{r}
telco = read_excel("data/Telco_customer_churn.xlsx")
```

## Feature Selection
```{r}
subdf = telco %>% 
  select(-c(CustomerID, Count, Country, State, City, `Zip Code`, 'Lat Long', Latitude, Longitude, 'Churn Reason', 'Churn Label', 'Churn Score', CLTV))
```

## Clean the subset dataframe
```{r}
colnames(subdf) = gsub(" ", "", colnames(subdf))

subdf = as.data.frame(lapply(subdf, function(x){ifelse(x=="No phone service", "No", x)}))
subdf = as.data.frame(lapply(subdf, function(x){ifelse(x=="No internet service", "No", x)}))

columns = colnames(subdf)[-c(5,18,19)] #exclude the columns we don't want to factor
subdf = subdf %>% mutate_at(columns, factor)
```

## Exploratory Data Analysis
### Numeric Variables
```{r}
churnpercent = prop.table(table(subdf$ChurnValue)) *100
pie(churnpercent, labels = paste(round(churnpercent, 2), "%" ,sep = ""))
```

### Factored Variables
```{r}
ggarrange(ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(Gender, position = 'fill')), 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(SeniorCitizen, position = 'fill')),
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(Partner, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(Dependents, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(PhoneService, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(MultipleLines, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(InternetService, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(OnlineSecurity, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(OnlineBackup, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(DeviceProtection, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(TechSupport, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(StreamingTV, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(StreamingMovies, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(Contract, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(PaperlessBilling, position = 'fill')) , 
          ggplot(data = subdf, aes(fill=ChurnValue)) +geom_bar(aes(PaymentMethod, position = 'fill')), 
          ncol = 4, nrow=4)
```


## Establish Baseline Accuracy using the ZeroR Classifier
```{r}
table(subdf$ChurnValue)
prop.table(table(subdf$ChurnValue))[1]
```
Baseline accuracy according to the ZeroR Classifier is 73.46%. In order for classifier to be useful, it needs to exceed this accuracy.

## Split dataset into Training and Testing Splits
```{r}
set.seed(123)
train = sample(1:nrow(subdf), nrow(subdf)*(.70))

trainSplit = subdf[train , ]
testSplit = subdf[-train , ]
```

## Logistic Regression
### Fit the model
```{r}
fit.glm = glm(ChurnValue ~., data = trainSplit, family = "binomial")

summary(fit.glm)
```

### Calculate Accuracy on TrainSplit
```{r}
glm.pred = ifelse(predict(fit.glm, trainSplit, type = "response") >= 0.5, 1, 0 )
cm.glm = confusionMatrix(as.factor(glm.pred), trainSplit$ChurnValue, positive = "1"); cm.glm
```

### Calculate Accuracy on TestSplit
```{r}
glm.pred = ifelse(predict(fit.glm, testSplit, type = "response") >= 0.5, 1, 0 )
cm.glm = confusionMatrix(as.factor(glm.pred), testSplit$ChurnValue, positive = "1"); cm.glm
```

## Decision Tree
### Fit the model
I will start off making a large tree and then prune it down, so I will use a low minsplit value of 2.
```{r}
fit.tree = rpart(ChurnValue ~ ., 
            data = trainSplit, 
            method = "class", 
            control = rpart.control(xval=10, minsplit = 2, cp=0),
            parms = list(split="gini"))
```

### Prune the large tree
To prune the tree, I will look for the complexity parameter that results in the minimum cross-validation (from the cptable); then I will use that CP value to prune the tree.
```{r}
bestcp = fit.tree$cptable[which.min(fit.tree$cptable[ , "xerror"]) , "CP"]; bestcp

fit.prune = prune.rpart(fit.tree, cp=bestcp)
```

### Calculate Accuracy on TrainSplit
```{r}
tree.pred = predict(fit.prune, trainSplit, type = "class")
cm.tree = confusionMatrix(tree.pred, trainSplit$ChurnValue, positive = "1"); cm.tree
```

### Calculate Accuracy on TestSplit
```{r}
tree.pred = predict(fit.prune, testSplit, type = "class")
cm.tree = confusionMatrix(tree.pred, testSplit$ChurnValue, positive = "1"); cm.tree
```

## Plotting ROC Curves and Comparing AUC
```{r}
plot.roc(testSplit$ChurnValue, glm.pred, col="red", print.auc=TRUE, legacy.axes=TRUE)
plot.roc(testSplit$ChurnValue, as.numeric(tree.pred), col="blue",print.auc=TRUE, print.auc.y=0.4, legacy.axes=TRUE, add=TRUE)
legend("bottomright", c("Logistic Regression", "Decision Tree"), col = c("red", "blue"), lwd=4)
```

## Conclusions
1) The logistic regression, according to the AUC, is a better predictor than the Decision Tree.

2) In comparing balanced accuracy, the logistic regression outperforms the baseline, but the decision tree classifier does not.

3) Both classifiers have fairly high negative predictive values, meaning that they are very good at predicting those who do not churn; however, both classifiers have weak positive predictive values, meaning that they aren't great at predicting those who do churn.




